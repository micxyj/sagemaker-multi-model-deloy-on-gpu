{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 部署已训练好的多个img2vec模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as f:\n",
    "    f.add('img2vec1.pth')\n",
    "    f.add('img2vec2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: 0: getcwd() failed: No such file or directory\n",
      "img2vec1.pth\n",
      "img2vec2.pth\n"
     ]
    }
   ],
   "source": [
    "!tar -tf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('lb-mme/model.tar.gz').upload_file('model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7fa39377b438>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import IdentitySerializer, JSONSerializer\n",
    "\n",
    "_time_tag = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model_s3_path = 's3://{}/lb-mme/model.tar.gz'.format(bucket)\n",
    "\n",
    "pytorch_serving_model = PyTorchModel(model_data=model_s3_path,\n",
    "                                     framework_version='1.6',\n",
    "                                     role=role,\n",
    "                                     entry_point='inference.py',\n",
    "                                     sagemaker_session=sess,\n",
    "                                     py_version='py3')\n",
    "\n",
    "_endpoint_name = 'lb-mme-' + _time_tag\n",
    "\n",
    "predictor = pytorch_serving_model.deploy(endpoint_name = _endpoint_name, instance_type='ml.g4dn.xlarge', initial_instance_count=1, serializer=JSONSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import base64\n",
    "\n",
    "\"\"\"import io\n",
    "\n",
    "with io.BytesIO() as output:\n",
    "    img_test.save(output, format=\"png\")\n",
    "    contents = output.getvalue()\"\"\"\n",
    "\n",
    "with open('dog.png', 'rb') as f:\n",
    "    img_bytes = f.read()\n",
    "    \n",
    "img_base = base64.encodebytes(img_bytes).decode()\n",
    "# stream = io.BytesIO(base64.b64decode(img_base.encode()))\n",
    "# img = Image.open(stream).convert('RGB')\n",
    "img_dic = {'target_model': 2, 'img_base': img_base}\n",
    "# img_json = json.dumps({'target_model': 1, 'img_base': img_base})\n",
    "# json.loads(img_json)['img_base'].encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream = io.BytesIO(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(stream).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9132,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "          [ 0.9132,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "          [ 0.9132,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "          ...,\n",
       "          [ 0.2796,  1.5639,  1.4098,  ...,  2.1975,  2.2147,  2.2489],\n",
       "          [ 0.2796,  1.5468,  1.5810,  ...,  2.1975,  2.2318,  2.2489],\n",
       "          [ 0.2624,  1.3927,  1.5125,  ...,  2.1975,  2.2489,  2.2489]],\n",
       "\n",
       "         [[ 1.0805,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "          [ 1.0805,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "          [ 1.0805,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "          ...,\n",
       "          [ 0.0476,  1.1681,  0.9930,  ...,  2.3235,  2.4286,  2.4286],\n",
       "          [ 0.0476,  1.1331,  1.1506,  ...,  2.3585,  2.4286,  2.4286],\n",
       "          [ 0.0126,  0.9930,  1.0980,  ...,  2.3761,  2.4286,  2.4286]],\n",
       "\n",
       "         [[ 1.3154,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 1.3154,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 1.3154,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          ...,\n",
       "          [-0.1835,  0.6705,  0.4439,  ...,  2.4308,  2.6226,  2.6226],\n",
       "          [-0.1661,  0.6705,  0.6356,  ...,  2.4831,  2.6051,  2.6226],\n",
       "          [-0.1661,  0.5659,  0.6008,  ...,  2.5354,  2.6051,  2.6226]]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictor.predict(img_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = res.tolist()['result'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
